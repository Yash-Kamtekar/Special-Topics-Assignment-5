{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP49obShTatr8YtNNR47oDZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yash-Kamtekar/Special-Topics-Assignment-5/blob/main/active_learning_with_lightly_ai_end2end.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P54SnJkVya8",
        "outputId": "93ecfa6a-0f95-4975-9294-3cfb78c83670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'clothing-dataset-small'...\n",
            "remote: Enumerating objects: 3839, done.\u001b[K\n",
            "remote: Counting objects: 100% (400/400), done.\u001b[K\n",
            "remote: Compressing objects: 100% (400/400), done.\u001b[K\n",
            "remote: Total 3839 (delta 9), reused 385 (delta 0), pack-reused 3439\u001b[K\n",
            "Receiving objects: 100% (3839/3839), 100.58 MiB | 32.35 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n",
            "Checking out files: 100% (3783/3783), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/alexeygrigorev/clothing-dataset-small.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install lightly as a pip package\n",
        "!pip install lightly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ecWe2vd_V8Q9",
        "outputId": "41034b4b-5ed0-46d9-fb70-4ab890f06479"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lightly\n",
            "  Downloading lightly-1.2.35-py3-none-any.whl (507 kB)\n",
            "\u001b[K     |████████████████████████████████| 507 kB 10.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.7/dist-packages (from lightly) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from lightly) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from lightly) (1.21.6)\n",
            "Collecting pytorch-lightning>=1.0.4\n",
            "  Downloading pytorch_lightning-1.8.1-py3-none-any.whl (798 kB)\n",
            "\u001b[K     |████████████████████████████████| 798 kB 58.3 MB/s \n",
            "\u001b[?25hCollecting lightly-utils~=0.0.0\n",
            "  Downloading lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from lightly) (0.13.1+cu113)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from lightly) (1.15.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.7/dist-packages (from lightly) (2022.9.24)\n",
            "Collecting hydra-core>=1.0.0\n",
            "  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 61.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.7/dist-packages (from lightly) (4.64.1)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.7/dist-packages (from lightly) (57.4.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from lightly) (2.23.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.0.0->lightly) (5.10.0)\n",
            "Collecting omegaconf~=2.2\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.6 MB/s \n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 64.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.0.0->lightly) (21.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from lightly-utils~=0.0.0->lightly) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf~=2.2->hydra-core>=1.0.0->lightly) (6.0)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.10.2-py3-none-any.whl (529 kB)\n",
            "\u001b[K     |████████████████████████████████| 529 kB 29.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.0.4->lightly) (1.12.1+cu113)\n",
            "Collecting lightning-utilities==0.3.*\n",
            "  Downloading lightning_utilities-0.3.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.0.4->lightly) (2022.10.0)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.0.4->lightly) (2.9.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.0.4->lightly) (4.1.1)\n",
            "Collecting fire\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (3.8.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (22.1.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (0.13.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (1.8.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.4->lightly) (6.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->hydra-core>=1.0.0->lightly) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->lightly) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->lightly) (2.10)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (1.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (3.19.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (2.14.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (1.50.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (0.38.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (3.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning>=1.0.4->lightly) (3.2.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire->lightning-utilities==0.3.*->pytorch-lightning>=1.0.4->lightly) (2.1.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, fire\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144576 sha256=708acc6593e8f838e060d365e3a2b1da57443702f51b12afa81aef6f0ac3e953\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115940 sha256=af3ab38d2a8417abfb5457bfa3c09f9539cd01479ed2c310d006bdb970293c8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "Successfully built antlr4-python3-runtime fire\n",
            "Installing collected packages: fire, antlr4-python3-runtime, torchmetrics, omegaconf, lightning-utilities, pytorch-lightning, lightly-utils, hydra-core, lightly\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 fire-0.4.0 hydra-core-1.2.0 lightly-1.2.35 lightly-utils-0.0.2 lightning-utilities-0.3.0 omegaconf-2.2.3 pytorch-lightning-1.8.1 torchmetrics-0.10.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your personal token for accessing the Lightly Platform is defined. You can get it from\n",
        "# the Lightly platform at https://app.lightly.ai under your username and then Preferences.\n",
        "LIGHTLY_TOKEN=\"7d9e3e942dbb8949325f955a838e79d822c3405cff6e0444\""
      ],
      "metadata": {
        "id": "weLiwjr0WL3y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!lightly-train input_dir=clothing-dataset-small/train trainer.max_epochs=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc7yDH9dXAsD",
        "outputId": "be10d868-6f4f-4b61-8d06-847368447098"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/hydra/_internal/hydra.py:127: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
            "See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
            "  configure_logging=with_log_configuration,\n",
            "/usr/local/lib/python3.7/dist-packages/lightly/cli/train_cli.py:69: UserWarning: Training a self-supervised model with a small batch size: 16! Small batch size may harm embedding quality. You can specify the batch size via the loader key-word: loader.batch_size=BSZ\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://storage.googleapis.com/models_boris/whattolabel-resnet18-simclr-d32-w1.0-i-085d0693.pth\" to /root/.cache/torch/hub/checkpoints/whattolabel-resnet18-simclr-d32-w1.0-i-085d0693.pth\n",
            "100% 42.8M/42.8M [00:01<00:00, 27.8MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py:23: LightningDeprecationWarning: pytorch_lightning.core.lightning.LightningModule has been deprecated in v1.7 and will be removed in v1.9. Use the equivalent class from the pytorch_lightning.core.module.LightningModule class instead.\n",
            "  \"pytorch_lightning.core.lightning.LightningModule has been deprecated in v1.7\"\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
            "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
            "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /content/lightly_outputs/2022-11-16/06-10-07/lightning_logs\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:601: UserWarning: Checkpoint directory /content/lightly_outputs/2022-11-16/06-10-07 exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name      | Type       | Params\n",
            "-----------------------------------------\n",
            "0 | model     | _SimCLR    | 11.2 M\n",
            "1 | criterion | NTXentLoss | 0     \n",
            "-----------------------------------------\n",
            "11.2 M    Trainable params\n",
            "0         Non-trainable params\n",
            "11.2 M    Total params\n",
            "44.762    Total estimated model params size (MB)\n",
            "Epoch 0:  26% 50/191 [00:14<00:40,  3.47it/s, loss=3.28, v_num=0][2022-11-16 06:10:30,678][numexpr.utils][INFO] - NumExpr defaulting to 2 threads.\n",
            "Epoch 0: 100% 191/191 [00:40<00:00,  4.75it/s, loss=3.1, v_num=0]`Trainer.fit` stopped: `max_epochs=1` reached.\n",
            "Epoch 0: 100% 191/191 [00:40<00:00,  4.71it/s, loss=3.1, v_num=0]\n",
            "Best model is stored at: \u001b[94m/content/lightly_outputs/2022-11-16/06-10-07/lightly_epoch_0.ckpt\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lightly-embed input_dir=clothing-dataset-small/train checkpoint=/content/lightly_outputs/2022-11-16/06-10-07/lightly_epoch_0.ckpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPgnuMWgXKBW",
        "outputId": "452911bd-4b7c-427a-d8ab-e91aa49b93c3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/hydra/_internal/hydra.py:127: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
            "See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
            "  configure_logging=with_log_configuration,\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py:23: LightningDeprecationWarning: pytorch_lightning.core.lightning.LightningModule has been deprecated in v1.7 and will be removed in v1.9. Use the equivalent class from the pytorch_lightning.core.module.LightningModule class instead.\n",
            "  \"pytorch_lightning.core.lightning.LightningModule has been deprecated in v1.7\"\n",
            "Compute efficiency: 0.16: 100% 3068/3068 [00:13<00:00, 232.62imgs/s]\n",
            "Embeddings are stored at \u001b[94m/content/lightly_outputs/2022-11-16/06-11-14/embeddings.csv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rename the embeddings output to embeddings.csv\n",
        "!mv /content/lightly_outputs/2022-11-16/06-11-14/embeddings.csv embeddings.csv"
      ],
      "metadata": {
        "id": "WRYW8J5mXNyK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the pip packages required for the tutorial if not already installed\n",
        "!pip install numpy\n",
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpHClUKnX9sJ",
        "outputId": "a5c6949e-91cc-402e-9ed2-ac6d0a29f1b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In the console output of the lightly-magic command, you find the filename of the created\n",
        "# embeddings file. We need this file later, so set the path to it as an environment variable.\n",
        "LIGHTLY_EMBEDDINGS_CSV=\"embeddings.csv\""
      ],
      "metadata": {
        "id": "7fOTtbJXXnid"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "from typing import List, Dict, Tuple\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from lightly.active_learning.agents.agent import ActiveLearningAgent\n",
        "from lightly.active_learning.config.selection_config import SelectionConfig\n",
        "from lightly.active_learning.scorers.classification import ScorerClassification\n",
        "from lightly.api.api_workflow_client import ApiWorkflowClient\n",
        "from lightly.openapi_generated.swagger_client import SamplingMethod"
      ],
      "metadata": {
        "id": "OAhDeSw2YDhd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = \"7d9e3e942dbb8949325f955a838e79d822c3405cff6e0444\"\n",
        "path_to_embeddings_csv = LIGHTLY_EMBEDDINGS_CSV\n",
        "# We define the client to the Lightly Platform API\n",
        "api_workflow_client = ApiWorkflowClient(token=token)\n",
        "api_workflow_client.create_dataset(dataset_name=\"active_learning_clothing_dataset\")"
      ],
      "metadata": {
        "id": "_tR_PfuwYJiL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_embeddings_csv = \"embeddings.csv\"\n",
        "YOUR_TOKEN = \"7d9e3e942dbb8949325f955a838e79d822c3405cff6e0444\"  # your token of the web platform\n",
        "YOUR_DATASET_ID = \"63747f4896ba509f0cd0aa62\"  # the id of your dataset on the web platform"
      ],
      "metadata": {
        "id": "CoBonEsNZlYg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run later\n",
        "!lightly-magic token='7d9e3e942dbb8949325f955a838e79d822c3405cff6e0444' dataset_id='63747f4896ba509f0cd0aa62' input_dir='clothing-dataset-small/train' trainer.max_epochs=20\n",
        "\n",
        "#!LIGHTLY_SERVER_LOCATION='https://api-dev.lightly.ai' lightly-upload input_dir=\"clothing-dataset-small/train\" token=\"8fe1f28d710558277de10fa50e31dca637f8e97306cdf3cf\" dataset_id=\"636ef6d6e2cafea9f47cc585\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bulsTMSRXWsB",
        "outputId": "d1fe59b3-2c8c-4251-a32f-e78a65d94e49"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/hydra/_internal/hydra.py:127: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
            "See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
            "  configure_logging=with_log_configuration,\n",
            "########## Starting to train an embedding model.\n",
            "/usr/local/lib/python3.7/dist-packages/lightly/cli/train_cli.py:69: UserWarning: Training a self-supervised model with a small batch size: 16! Small batch size may harm embedding quality. You can specify the batch size via the loader key-word: loader.batch_size=BSZ\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py:23: LightningDeprecationWarning: pytorch_lightning.core.lightning.LightningModule has been deprecated in v1.7 and will be removed in v1.9. Use the equivalent class from the pytorch_lightning.core.module.LightningModule class instead.\n",
            "  \"pytorch_lightning.core.lightning.LightningModule has been deprecated in v1.7\"\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
            "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
            "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /content/lightly_outputs/2022-11-16/06-13-24/lightning_logs\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:601: UserWarning: Checkpoint directory /content/lightly_outputs/2022-11-16/06-13-24 exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name      | Type       | Params\n",
            "-----------------------------------------\n",
            "0 | model     | _SimCLR    | 11.2 M\n",
            "1 | criterion | NTXentLoss | 0     \n",
            "-----------------------------------------\n",
            "11.2 M    Trainable params\n",
            "0         Non-trainable params\n",
            "11.2 M    Total params\n",
            "44.762    Total estimated model params size (MB)\n",
            "Epoch 0:  26% 50/191 [00:09<00:27,  5.20it/s, loss=3.28, v_num=0][2022-11-16 06:13:37,856][numexpr.utils][INFO] - NumExpr defaulting to 2 threads.\n",
            "Epoch 19: 100% 191/191 [00:30<00:00,  6.28it/s, loss=2.05, v_num=0]`Trainer.fit` stopped: `max_epochs=20` reached.\n",
            "Epoch 19: 100% 191/191 [00:30<00:00,  6.22it/s, loss=2.05, v_num=0]\n",
            "Best model is stored at: \u001b[94m/content/lightly_outputs/2022-11-16/06-13-24/lightly_epoch_13.ckpt\u001b[0m\n",
            "########## Starting to embed your dataset.\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py:23: LightningDeprecationWarning: pytorch_lightning.core.lightning.LightningModule has been deprecated in v1.7 and will be removed in v1.9. Use the equivalent class from the pytorch_lightning.core.module.LightningModule class instead.\n",
            "  \"pytorch_lightning.core.lightning.LightningModule has been deprecated in v1.7\"\n",
            "Compute efficiency: 0.58: 100% 3068/3068 [00:11<00:00, 258.66imgs/s]\n",
            "Embeddings are stored at \u001b[94m/content/lightly_outputs/2022-11-16/06-13-24/embeddings.csv\u001b[0m\n",
            "########## Starting to upload your dataset to the Lightly platform.\n",
            "Uploading \u001b[92m3068\u001b[0m images (with \u001b[92m2\u001b[0m workers).\n",
            "100% 3068/3068 [19:22<00:00,  2.64imgs/s]\n",
            "Finished the upload of the dataset.\n",
            "Finished upload of embeddings.\n",
            "########## Finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CSVEmbeddingDataset:\n",
        "    def __init__(self, path_to_embeddings_csv: str):\n",
        "        with open(path_to_embeddings_csv, 'r') as f:\n",
        "            data = csv.reader(f)\n",
        "\n",
        "            rows = list(data)\n",
        "            header_row = rows[0]\n",
        "            rows_without_header = rows[1:]\n",
        "\n",
        "            index_filenames = header_row.index('filenames')\n",
        "            filenames = [row[index_filenames] for row in rows_without_header]\n",
        "\n",
        "            index_labels = header_row.index('labels')\n",
        "            labels = [row[index_labels] for row in rows_without_header]\n",
        "\n",
        "            embeddings = rows_without_header\n",
        "            indexes_to_delete = sorted([index_filenames, index_labels], reverse=True)\n",
        "            for embedding_row in embeddings:\n",
        "                for index_to_delete in indexes_to_delete:\n",
        "                    del embedding_row[index_to_delete]\n",
        "\n",
        "        # create the dataset as a dictionary mapping from the filename to a tuple of the embedding and the label\n",
        "        self.dataset: Dict[str, Tuple[np.ndarray, int]] = \\\n",
        "            dict([(filename, (np.array(embedding_row, dtype=float), int(label)))\n",
        "                  for filename, embedding_row, label in zip(filenames, embeddings, labels)])\n",
        "\n",
        "    def get_features(self, filenames: List[str]) -> np.ndarray:\n",
        "        features_array = np.array([self.dataset[filename][0] for filename in filenames])\n",
        "        return features_array\n",
        "\n",
        "    def get_labels(self, filenames: List[str]) -> np.ndarray:\n",
        "        labels = np.array([self.dataset[filename][1] for filename in filenames])\n",
        "        return labels"
      ],
      "metadata": {
        "id": "Jz9aID4XYGyC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CSVEmbeddingDataset(path_to_embeddings_csv=path_to_embeddings_csv)\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "agent = ActiveLearningAgent(api_workflow_client=api_workflow_client)"
      ],
      "metadata": {
        "id": "2SU8iyzCYmKF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting the initial selection\")\n",
        "selection_config = SelectionConfig(n_samples=200, method=SamplingMethod.CORESET, name='initial-selection')\n",
        "agent.query(selection_config=selection_config)\n",
        "print(f\"There are {len(agent.labeled_set)} samples in the labeled set.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqVcpl4fgkQ1",
        "outputId": "ce431cff-c4c7-431a-feaf-7495efb76b04"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting the initial selection\n",
            "There are 200 samples in the labeled set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_set_features = dataset.get_features(agent.labeled_set)\n",
        "labeled_set_labels = dataset.get_labels(agent.labeled_set)\n",
        "classifier.fit(X=labeled_set_features, y=labeled_set_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF-YRR80g0uQ",
        "outputId": "98699a12-fe8d-41bf-b332-f7a2a2ca8324"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_set_features = dataset.get_features(agent.query_set)\n",
        "predictions = classifier.predict_proba(X=query_set_features)"
      ],
      "metadata": {
        "id": "OVHWPmRyg4O-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "active_learning_scorer = ScorerClassification(model_output=predictions)"
      ],
      "metadata": {
        "id": "vAyjligKg45J"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selection_config = SelectionConfig(n_samples=300, method=SamplingMethod.CORAL, name='al-iteration-1')\n",
        "agent.query(selection_config=selection_config, al_scorer=active_learning_scorer)\n",
        "print(f\"There are {len(agent.labeled_set)} samples in the labeled set.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSz-gqjig7Oo",
        "outputId": "494a101a-e689-4659-d957-10bc15662fdb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 300 samples in the labeled set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_set_features = dataset.get_features(agent.labeled_set)\n",
        "labeled_set_labels = dataset.get_labels(agent.labeled_set)\n",
        "classifier.fit(X=labeled_set_features, y=labeled_set_labels)\n",
        "\n",
        "# evaluate on unlabeled set\n",
        "unlabeled_set_features = dataset.get_features(agent.unlabeled_set)\n",
        "unlabeled_set_labels = dataset.get_labels(agent.unlabeled_set)\n",
        "accuracy_on_unlabeled_set = classifier.score(X=unlabeled_set_features, y=unlabeled_set_labels)\n",
        "print(f\"accuracy on unlabeled set: {accuracy_on_unlabeled_set}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xo3o0LIhB5-",
        "outputId": "73cfb8ac-ff4a-44c5-d22a-8fbc30e51b4e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on unlabeled set: 0.3800578034682081\n"
          ]
        }
      ]
    }
  ]
}